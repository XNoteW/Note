## 计算图

有一个 $m$ 维随机向量 $X = (X_1, X_2, \cdots, X_m)^T$, 其中 $X_1, X_2, \cdots, X_m$ 独立同分布, 存在一个统计量 $Z = g(X) = XW$. 即 $Z = X_1W_1 + X_2W_2 + \cdots + X_mW_m$.

将 $X_1, X_2, \cdots, X_m, Z$ 当作概率图模型的节点, 便会有

$$
p(Z, X) = \displaystyle\sum_{i=1}^m p(X_i)p(Z|X_i) = P(X)^TP(Z|X)
$$

这样, 便可得到一个单层神经网络模型.

下面以图像分类为例来说明该模型. 假设有数据集 $\{(x^{(i)}, y^{(i)})\}_{i=1}^m$, 其中 $x^{(i)}$ 由 $3$ 数组来表示一张彩色图片; $y^{(i)} \in \{0, 1, 2, \cdots, c-1\}$ ($c$ 表示该数据集中图片的类别总数). 一般地, 机器学习领域均假设 $x^{(1)}, x^{(2)}, \cdots, x^{(m)}$ 独立同分布. 令 $X = (x^{(1)}, x^{(2)}, \cdots, x^{(m)})^T$, 则统计量 $Z = g(X) = \phi(X)W$ 亦可看作是随机变量.