# 基础设定

设 $(\Omega, \mathcal{F}, P)$ 为**概率空间**. $\mathcal{X} =(X_1, X_2, \cdots, X_n)$, $\mathcal{Y} = (Y_1,Y_2, \cdots, Y_n)$ 均是 $n$ 元**随机向量**.

使用 $Val(\mathcal{X})$ 表示 $\mathcal{X}$ 可以取值的集合. 即若 $x \in Val(\mathcal{X})$, 则有 $X_1 = x_1, X_2=x_2, \cdots, X_n = x_n$, 其中 $x = (x_1,x_2,\cdots, x_n)$. 对任意 $i$, 使用 $P(X_i)$ 表示 $X_i$ 的**边缘分布** (marginal distribution); $(X_1, X_2, \cdots, X_n)$ 表示**联合**(joint)**分布**. 使用 $P(X_i|Y_j)$ 表示条件概率分布集合. 这样, 我们可以将链式法则简写为 $P(X_i,Y_j) = P(X_i)P(Y_j|X_i)$. 更有

$$
P(X_1, X_2, \cdots, X_k) = P(X_1)P(X_2|X_1)\cdots P(X_k|X_{k-1})
$$

下面考虑监督学习:

称 $\mathcal{X}$ 为**输入空间**, **属性空间**, 或**样本空间**,  $\mathcal{Y}$ 称为**标记空间** (label space) 或**输出空间**. 考虑 $m$ 个样本 $\{x^{(1)}, x^{(2)}, \cdots, x^{(m)}\} \subseteq  Val{(\mathcal{X})}$. 设 $\phi = (\phi_1,\phi_2,\cdots,\phi_p)^T$ 为基函数向量, 则称

$$
\begin{aligned}
\Phi &= \phi(x^{(1)}, x^{(2)}, \cdots, x^{(m)})^T\\
&= \begin{pmatrix}
\phi_1(x^{(1)}) &\phi_2(x^{(1)})& \cdots &\phi_p(x^{(1)}) \\
\phi_1(x^{(2)}) &\phi_2(x^{(2)}) &\cdots &\phi_p(x^{(2)})\\
\vdots & \vdots & \ddots & \vdots\\
\phi_1(x^{(m)}) &\phi_2(x^{(m)}) &\cdots &\phi_p(x^{(m)})\\
\end{pmatrix}
\end{aligned}
$$

为**设计矩阵**.

假设任意 $x \in Val{(\mathcal{X})}$ 符合 (fit) **基于参数的线性模型**:

$$
f_{\theta}(x) = \displaystyle\sum_{i=1}^p \theta_i \phi_i(x) = \theta^T\phi(x)
$$

其中参数 $\theta \in \mathbb{R}^p$.

【定义1】设 $A$ 是 $n$ 阶埃尔米特矩阵 ($A^{\text{H}}=A$), 若对于任意 $n$ 维向量 $x$ 都有

$$
x^{\text{H}}Ax \geq 0
$$

则称 $A$ 为非负定 (**半正定**) 矩阵, 记作 $A\geq 0$; 若对于任意 $n$ 维向量 $x$ 都有

$$
x^{\text{H}}Ax > 0
$$

则称 $A$ 为**正定矩阵**, 记作 $A>0$.