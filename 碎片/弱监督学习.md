# 弱监督学习

南京大学周志华教授发表的一篇论文《A brief introduction to weakly supervised learning》，中文详解见：[机器之心](https://mp.weixin.qq.com/s?__biz=MjM5MzM3NjM4MA==&mid=2654689308&idx=2&sn=e8381137a99875cfee71ed8d3c99d0b5&chksm=bd58090f8a2f80195afe7137318efc1063d0608b440a1a36a567eb7fe330caacee6b5d7e1ef9&mpshare=1&scene=23&srcid=1001tduadHRH9driq6NhU3EQ#rd)

- [论文下载](https://cs.nju.edu.cn/zhouzh/zhouzh.files/publication/nsr18.pdf)

## 不完全监督(Incomplete Supervision)

不完全监督是指只有一个训练集的子集被给予了标签，而剩下的数据并没有任何标签；任务的目标是学习一个目标函数 $f:\mathcal{X}\mapsto \mathcal{Y}$，其训练集的数据来自一个集合 $\mathcal{D}=\{(x_1, y_1), \ldots, (x_l,y_l), \ldots, x_{l+1}, x_m\}$。其中 $l$ 代表了有标记训练集的数量， $u=m-l$ 代表了无标记实例的数量；
对于不完全监督有两种主要的技术类型：**主动学习**(active learning)和**半监督学习**(semi-supervised learning)。

### 主动学习(active learning)

主动学习假设存在一个“神谕”(oracle)，比如人类专家，可以选择出未标记的实例，向他询问获取标签的真值；所以主动学习的目标是最小化疑问的数量，这样便可以最小化为了获取一个好的模型所付出的标记代价；

主动学习尝试选择最有用的未标记实例进行询问。目前存在两种广泛应用的选择标准(selection criteria)：**信息量**和**代表性**(informativeness and representativeness)

其中 informativeness 衡量了未标记实例帮助减少统计模型不确定性的程度。基于信息量选择标准的代表方法有**不确定采样**(uncertainty sampling)和**委员会投票**(query-by-committee)两种：

- 不确定采样(uncertainty sampling)：训练一个学习器，学习机对最不自信的未标记实例的类别进行询问；
- 委员会投票(query-by-committee)：生成多个学习器，对学习器之间矛盾最大的未标记实例的类别进行询问；

基于代表性(representativeness)的方法针对未标记数据使用聚类方法开发一种聚类结构；
两种选择标准的缺点：基于信息量(informativeness)的方法严重的依赖标记数据，需要依靠它们来构建初始模型，选择需要进行询问的实例。当标记的样本实例数目过少时，模型的表现往往很不稳定；基于代表性(representativeness)的方法严重依赖于由未标记数据控制的聚类结果；

### 半监督学习(semi-supervised learning)

半监督学习尝试自动地利用未标记数据而不需要想人类专家进行询问；

## 不确切监督(inexact supervision)

不确切监督(inexact supervision)关心一些监督信息已经给予，但是并没有渴望的那么确切的情况。比如对于药物活性预测的情况，目标是建立一个模型来预测一个新的分子是否合适用于制作一个特殊药剂。然而一个分子可能具有多种能态，人类专家只知道哪种分子合适或不合适，却不知道什么特殊的能态来决定；

这个任务的目标是学习$f:\mathcal{X}\mapsto \mathcal{Y}$，其训练集的数据来自一个集合$\mathcal{D}=\{(X_{1}, y_{1}), \ldots,(X_{m}, y_{m})\}$，其中$X_{i}=\{x_{i1}, \ldots, x_{im_{i}}\} \subseteq \mathcal{X}$ 被称作一个包(bag)，$x_{ij}\in\mathcal{X}(j\in\{1, \ldots, m_{i}\})$是一个实例，$m_{i}$是$X_{i}$包中的实例数，$y_{i}\in\mathcal{Y}=\{Y,N\}$。如果在$X_{i}$包中存在一个$x_{ip}$实例为正例，则$X_{i}$包为正包。目标是对未见到的包预测其标签，这被称作**多实例学习**(multi-instance learning).

几乎所有的监督学习算法都有它们各自的多实例学习版本：
大多数算法尝试通过改变它们的注意力从实例的辨别到包的辨别，将单实例监督学习转变为多实例学习；
一些其他算法尝试通过表示转换(representation transformation)来适应多实例表示；

多实例学习算法还可以被分类为：

- 示例空间范式(instance-space paradigm)，集中了实例级别的响应；
- 包空间范式(bag-space paradigm)，包被看做成一个整体；
- 嵌入空间范式(embedded-space paradigm)，学习算法在嵌入式特征空间中学习；

**包生成器**(bag generator)指定了实例如何生成一个包；

其他研究：多实例学习算法还有一个目标是辨别导致正包变为正的关键实例(key instance)。标准的多实例学习假设每一个正包都必须有一个关键实例，目前还有研究假设没有关键实例或每个实例对包的标签贡献相同的情形；

很多理论研究显示，多实例学习很难学习异质情形(hererogeneous case)，此时包中的每一个实例使用一个不同的规则来进行分类；

## 不准确监督(inaccurate supervision)

不准确监督关注监督信息并不一致是真值的情况，即一些标注信息可能存在错误；
一个典型的方法是标注噪声下学习，很多理论的研究假定标签存在随机的分类噪声；
基本的思想是分辨出潜在的误分类样本，然后尝试做出修正；

**数据编辑方法**(data editing approach)构建一个相对邻域图(relative neighborhood graph)，每一个节点对应一个训练样本，每一个连接两个不同标签节点的边被称作切边(cut edge)。然后测量一个切边的权重统计量，直觉上来看，如果一个实例连接了太多的切边，则该实例是可疑的。刻意的实例将被删除或被重新标记。缺点：该方法依赖于咨询邻域信息，因此在高纬度特征空间中，它将变得不可靠，因为当数据稀疏时，邻域识别将变得不可靠；

近期出现的有趣的不准确监督的场景是众包模式，这是一种流行的将工作外包给个人的范式。对于机器学习来说，用众包模式为训练数据收集标签是一种经济的方式。具体来说，未标记的数据被外包给大量的工人来标记。在著名的众包系统 Amazon Mechanical Turk 上，用户可以提交一项任务，例如将图片标注为「树」或「非树」，然后职工完成工作以获取少量报酬。通常这些工人来自世界各地，每个人都可以执行多个任务。这些职工通常互相独立，报酬不高，并通过自己的判断标记数据。这些职工的标记质量参差不齐，但标记质量信息对于用户来说是不可见的，因为工人的身份是保密的。在这些职工中可能存在「垃圾制造者」，几乎用随机的标签来标记数据（例如，用机器替代人类赚取报酬），或「反抗者」，故意给出错误的标签。此外，某些任务可能对一些人来说太难而无法完成。使用众包返回的不准确监督信息来保证学习性能是非常困难的。

很多研究尝试用众包标签推断真值标签。多数人投票策略得到了集成方法 [35] 的理论支持，在实践中得到了广泛使用并有很好的表现 [75,76]，因此通常作为基线标准。如果预期可以对工人质量和任务难度建模，那么通过为不同的工人在不同的任务上设置权重，则可以获得更好的效果。为此，一些方法尝试构建概率模型然后使用 EM 算法进行评估 [77,78]。人们也使用了极小极大熵方法 [35]。概率模型可以用于移除垃圾制造者 [79]。近期人们给出了移除低质量工人的一般理论条件 [80]。

在机器学习中，众包通常用于收集标签，在实践中，模型的最终性能，而不是这些标签的质量，才是更重要的。目前已有很多关于从低能老师和众包标签学习的研究 [81,82]，这和用带噪声标签学习是很接近的。但其中的区别在于，对于众包设定而言，人们可以方便地、重复地对某个示例提取众包标签。因此，在众包数据学习中，考虑经济性和最小化众包标签的充分数量是很重要的，即有效众包学习的最小代价 [83]。很多研究专注于任务分配和预算分配，尝试在准确率和标注开销之间取得平衡。为此，非适应性的任务分配机制（离线分配任务 [84,85]）和适应性机制（在线分配任务 [86,87]）都得到了在理论支持下的研究。需要注意的是，多数研究采用了 Dawid–Skene 模型 [88]，其假设不同任务的潜在成本是相同的，而没有探索更复杂的成本设置。

设计一个有效的众包协议也是很重要的。在文献 [89] 中提供了「不确定」选项，从而使工人在不确定的时候不被迫使给出确定的标签。该选项可以帮助标记的可靠性获得有理论支持 [90] 的提升。在文献 [91] 中提出了一种「double or nothing」的激励兼容机制，以确保工人能提供基于其自己的信心的标注，诚实地工作。在假定每位工人都希望最大化他们的报酬的前提下，该协议被证实可以避免垃圾制造者的出现。

## 结论

监督学习技术在具备强监督信息（如大量具备真值标签的训练样本）的情况中取得了很大成功。然而，在实际任务中，收集监督信息需要大量成本，因此，使用弱监督学习通常是更好的方式。

本文主要介绍三种典型的弱监督：不完全、不确切和不准确监督。尽管三者可以分开讨论，但是实践中它们通常同时出现，如图 1 所示，以往研究中也讨论过此类「混合」案例 [52,92,93]。此外，还存在其他类型的弱监督。例如，主要通过强化学习方法解决 [94] 的延时监督也属于弱监督。由于篇幅限制，本文实际上扮演了更多文献索引而非文献综述的角色。对细节感兴趣的读者请阅读对应参考文献。近期越来越多的研究者关注弱监督学习，如部分监督学习主要关注不完全监督学习 [95]，同时也有很多关于弱监督的其他讨论 [96,97]。

为了简化讨论，本文主要关注二分类，尽管大部分讨论经过稍微改动就可以扩展到多类别或回归学习。注意，多类别任务中可能会出现更复杂的情景 [98]。如果考虑到多标签学习 [99]，即每个样本同时关联到多个标签的任务，则情况更加复杂。以不完全监督为例，除了标注／非标注示例以外，多标签任务可能遇到部分标注示例，即训练示例中，只有部分标签是真值 [100]。即使只考虑标注／未标注数据，其设计选项也比单标签设置多。如对于积极学习而言，给出一个非标注示例，在多标签任务中可以要求给出该示例的所有标签 [101]、特定标签 [102]，或一对标签的相关性排序 [103]。然而，不管是哪种数据和任务，弱监督学习都变得越来越重要。